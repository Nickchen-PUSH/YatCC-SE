"""Kubernetes é›†ç¾¤æµ‹è¯•

æµ‹è¯• Kubernetes é›†ç¾¤çš„ç”¨æˆ·ç‹¬ç«‹ code-server éƒ¨ç½²åŠŸèƒ½ã€‚
"""

import unittest
import asyncio as aio
import socket
import urllib.request
import urllib.error
from urllib.parse import urlparse
from cluster import JobInfo, ClusterError, JobNotFoundError
from base.logger import logger
from . import ClusterTestBase, RUNNER, get_kubernetes_cluster, ensure_kubernetes_cluster

LOGGER = logger(__spec__, __file__)


def setUpModule() -> None:
    """æ¨¡å—çº§åˆ«çš„è®¾ç½®"""
    LOGGER.info("ğŸš€ Kubernetes cluster test module setup")
    # é¢„å…ˆåˆå§‹åŒ– Kubernetes é›†ç¾¤
    try:
        k8s_cluster = ensure_kubernetes_cluster()
        if k8s_cluster:
            LOGGER.info(f"âœ… Kubernetes cluster ready for testing: {k8s_cluster.__class__.__name__}")
        else:
            LOGGER.warning("âš ï¸  No Kubernetes cluster available")
    except Exception as e:
        LOGGER.warning(f"âš ï¸  Failed to setup Kubernetes cluster: {e}")


def tearDownModule() -> None:
    """æ¨¡å—çº§åˆ«çš„æ¸…ç†"""
    LOGGER.info("ğŸ§¹ Kubernetes cluster test module teardown")


class KubernetesClusterTest(ClusterTestBase):
    """Kubernetes é›†ç¾¤åŠŸèƒ½æµ‹è¯•"""
    
    def setUp(self) -> None:
        """æµ‹è¯•è®¾ç½®"""
        super().setUp()
        
        # è·å– Kubernetes é›†ç¾¤
        k8s_cluster = get_kubernetes_cluster()
        
        if k8s_cluster is None:
            self.skipTest("No Kubernetes cluster available for testing")
        
        self.cluster = k8s_cluster
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®çš„ Kubernetes é›†ç¾¤
        is_mock = getattr(self.cluster, '_is_mock', True)
        if is_mock:
            LOGGER.info(f"Using MOCK cluster for Kubernetes tests: {self.cluster.__class__.__name__}")
            self.is_real_k8s = False
        else:
            LOGGER.info(f"Using REAL Kubernetes cluster: {self.cluster.__class__.__name__}")
            self.is_real_k8s = True
        
        self.assertIsNotNone(self.cluster, "Kubernetes cluster should be available")
    
    def test_create_job_deployment_status(self):
        """æµ‹è¯•åˆ›å»ºä½œä¸šå¹¶éªŒè¯ deployment è¿è¡ŒçŠ¶æ€"""
        async def test_logic():
            LOGGER.info("ğŸ§ª Testing job creation and deployment status...")
            
            # åˆ›å»ºæµ‹è¯•ç”¨æˆ·çš„ code-server ä½œä¸šå‚æ•°
            user_id = 2001
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="test-workspace",
                memory_limit="512Mi",
                cpu_limit="500m"
            )
            
            LOGGER.info(f"ğŸ“ Creating job for user {user_id}...")
            
            # æäº¤ä½œä¸š
            job_info = await self.cluster.submit_job(job_params)
            
            # è®°å½•ä½œä¸šIDç”¨äºæ¸…ç†
            self.track_job(job_info.id)
            
            # éªŒè¯ä½œä¸šä¿¡æ¯
            self.assert_code_server_job_valid(job_info)
            self.assertEqual(job_info.user_id, user_id)
            self.assertIsNotNone(job_info.service_url)
            
            LOGGER.info(f"âœ… Job created: {job_info.id}")
            LOGGER.info(f"ğŸ“ Service URL: {job_info.service_url}")
            
            if self.is_real_k8s:
                # å¯¹äºçœŸå®çš„ Kubernetes é›†ç¾¤ï¼Œç­‰å¾… deployment å°±ç»ª
                LOGGER.info("â³ Waiting for deployment to be ready...")
                
                # ç­‰å¾…ä½œä¸šçŠ¶æ€å˜ä¸º RUNNINGï¼ˆæœ€å¤šç­‰å¾…60ç§’ï¼‰
                ready = await self.wait_for_job_status(job_info.id, JobInfo.Status.RUNNING, timeout=60)
                
                if ready:
                    LOGGER.info("âœ… Deployment is running")
                    
                    # éªŒè¯æœ€ç»ˆçŠ¶æ€
                    final_status = await self.cluster.get_job_status(job_info.id)
                    self.assertEqual(final_status, JobInfo.Status.RUNNING)
                    
                    # è·å–æœ€æ–°çš„ä½œä¸šä¿¡æ¯
                    updated_job_info = await self.cluster.get_job_info(job_info.id)
                    self.assert_code_server_job_valid(updated_job_info)
                    self.assertEqual(updated_job_info.status, JobInfo.Status.RUNNING)
                    
                else:
                    LOGGER.warning("âš ï¸  Deployment did not reach RUNNING state within timeout")
                    # è·å–å½“å‰çŠ¶æ€ç”¨äºè°ƒè¯•
                    current_status = await self.cluster.get_job_status(job_info.id)
                    LOGGER.warning(f"Current status: {current_status}")
                    
                    # å¯¹äºæµ‹è¯•ï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºè¿™æ˜¯å¯æ¥å—çš„ï¼Œå› ä¸ºå¯èƒ½æ˜¯èµ„æºé™åˆ¶
                    self.assertIn(current_status, [
                        JobInfo.Status.PENDING, 
                        JobInfo.Status.RUNNING,
                        JobInfo.Status.FAILED
                    ])
            else:
                # å¯¹äº Mock é›†ç¾¤ï¼ŒçŠ¶æ€åº”è¯¥ç«‹å³ä¸º RUNNING
                self.assertEqual(job_info.status, JobInfo.Status.RUNNING)
                LOGGER.info("âœ… Mock deployment is running")
            
            return job_info
        
        return RUNNER.run(test_logic())

    def test_duplicate_job_creation_same_user(self):
        """æµ‹è¯•é‡å¤åˆ›å»ºç›¸åŒç”¨æˆ·çš„ä½œä¸šæ˜¯å¦ä¼šé‡å¤åˆ›å»º deployment"""
        async def test_logic():
            LOGGER.info("ğŸ§ª Testing duplicate job creation for same user...")
            
            user_id = 2002
            
            # ç¬¬ä¸€æ¬¡åˆ›å»ºä½œä¸š
            job_params_1 = self.create_code_server_params(
                user_id=user_id,
                workspace_name="workspace-1",
                memory_limit="256Mi"
            )
            
            LOGGER.info(f"ğŸ“ Creating first job for user {user_id}...")
            job_info_1 = await self.cluster.submit_job(job_params_1)
            self.track_job(job_info_1.id)
            
            LOGGER.info(f"âœ… First job created: {job_info_1.id}")
            
            # ç­‰å¾…ä¸€ç§’ç¡®ä¿æ—¶é—´æˆ³ä¸åŒ
            await aio.sleep(1)
            
            # ç¬¬äºŒæ¬¡åˆ›å»ºç›¸åŒç”¨æˆ·çš„ä½œä¸šï¼ˆåº”è¯¥é‡ç”¨æˆ–æ›´æ–°ç°æœ‰ deploymentï¼‰
            job_params_2 = self.create_code_server_params(
                user_id=user_id,
                workspace_name="workspace-2",
                memory_limit="512Mi",  # ä¸åŒçš„èµ„æºé…ç½®
                env={"UPDATED": "true"}  # ä¸åŒçš„ç¯å¢ƒå˜é‡
            )
            
            LOGGER.info(f"ğŸ“ Creating second job for user {user_id}...")
            job_info_2 = await self.cluster.submit_job(job_params_2)
            
            # å¦‚æœè¿”å›äº†ä¸åŒçš„ä½œä¸šIDï¼Œä¹Ÿè¦è·Ÿè¸ª
            if job_info_2.id != job_info_1.id:
                self.track_job(job_info_2.id)
            
            LOGGER.info(f"âœ… Second job processed: {job_info_2.id}")
            
            # éªŒè¯è¡Œä¸ºï¼šåº”è¯¥é‡ç”¨ç°æœ‰çš„ deployment æˆ–è€…æ›´æ–°å®ƒ
            if self.is_real_k8s:
                # å¯¹äºçœŸå®çš„ Kubernetes é›†ç¾¤ï¼Œæ£€æŸ¥å®é™…çš„ deployment è¡Œä¸º
                
                # æ–¹å¼1: åŒä¸€ä¸ª deployment è¢«æ›´æ–°
                if job_info_1.id == job_info_2.id:
                    LOGGER.info("âœ… Same deployment reused and updated")
                    self.assertEqual(job_info_1.id, job_info_2.id)
                    self.assertEqual(job_info_1.user_id, job_info_2.user_id)
                    
                    # éªŒè¯é…ç½®å·²æ›´æ–°
                    updated_job = await self.cluster.get_job_info(job_info_2.id)
                    self.assertIn("UPDATED", updated_job.env)
                    
                # æ–¹å¼2: æ—§çš„è¢«æ›¿æ¢ï¼Œæ–°çš„è¢«åˆ›å»ºï¼ˆå–å†³äºå®ç°ç­–ç•¥ï¼‰
                else:
                    LOGGER.info("â„¹ï¸  New deployment created, old one should be cleaned up")
                    self.assertNotEqual(job_info_1.id, job_info_2.id)
                    self.assertEqual(job_info_1.user_id, job_info_2.user_id)
                    
                    # éªŒè¯æ—§çš„ä½œä¸šçŠ¶æ€ï¼ˆå¯èƒ½è¢«æš‚åœæˆ–åˆ é™¤ï¼‰
                    try:
                        old_status = await self.cluster.get_job_status(job_info_1.id)
                        LOGGER.info(f"Old job status: {old_status}")
                        # æ—§ä½œä¸šåº”è¯¥ä¸å†æ˜¯ RUNNING çŠ¶æ€
                        self.assertNotEqual(old_status, JobInfo.Status.RUNNING)
                    except JobNotFoundError:
                        LOGGER.info("âœ… Old job was properly cleaned up")
                
                # éªŒè¯æ–°ä½œä¸šæ˜¯æ´»è·ƒçš„
                final_job = await self.cluster.get_job_info(job_info_2.id)
                self.assert_code_server_job_valid(final_job)
                self.assertEqual(final_job.user_id, user_id)
                
            else:
                # å¯¹äº Mock é›†ç¾¤ï¼ŒéªŒè¯é¢„æœŸçš„è¡Œä¸º
                LOGGER.info("ğŸ­ Verifying mock cluster behavior...")
                
                # Mock é›†ç¾¤åº”è¯¥é‡ç”¨ç›¸åŒç”¨æˆ·çš„ deployment
                self.assertEqual(job_info_1.user_id, job_info_2.user_id)
                
                # éªŒè¯æœ€æ–°çš„ä½œä¸šä¿¡æ¯
                latest_job = await self.cluster.get_job_info(job_info_2.id)
                self.assert_code_server_job_valid(latest_job)
            
            return job_info_1, job_info_2
        
        return RUNNER.run(test_logic())

    def test_delete_job_suspension_behavior(self):
        """æµ‹è¯• delete_job æ˜¯å¦åªæ˜¯ä¸´æ—¶å…³é—­ deployment è€Œä¸æ˜¯å®Œå…¨åˆ é™¤"""
        async def test_logic():
            LOGGER.info("ğŸ§ª Testing delete_job suspension behavior...")
            
            user_id = 5001
            
            # 1. åˆ›å»ºæµ‹è¯•ä½œä¸š
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="suspension-test",
                memory_limit="256Mi",
                env={"TEST_VAR": "original_value"}
            )
            
            LOGGER.info(f"ğŸ“ Creating job for suspension test (user {user_id})...")
            job_info = await self.cluster.submit_job(job_params)
            self.track_job(job_info.id)
            
            original_job_id = job_info.id
            LOGGER.info(f"âœ… Job created: {original_job_id}")
            
            # éªŒè¯ä½œä¸šæ­£åœ¨è¿è¡Œ
            initial_status = await self.cluster.get_job_status(original_job_id)
            LOGGER.info(f"ğŸ“Š Initial status: {initial_status}")
            
            if self.is_real_k8s:
                # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿ deployment å¯åŠ¨
                await aio.sleep(5)
            
            # 2. è·å– deployment çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæš‚åœå‰ï¼‰
            if self.is_real_k8s:
                original_deployment = await aio.to_thread(
                    self.cluster.apps_v1.read_namespaced_deployment,
                    name=original_job_id,
                    namespace=self.cluster.config.Kubernetes.NAMESPACE
                )
                original_replicas = original_deployment.spec.replicas
                original_annotations = original_deployment.metadata.annotations or {}
                
                LOGGER.info(f"ğŸ“Š Original replicas: {original_replicas}")
                LOGGER.info(f"ğŸ“Š Original annotations: {original_annotations}")
            
            # 3. è°ƒç”¨ delete_job è¿›è¡Œæš‚åœ
            LOGGER.info(f"â¸ï¸  Calling delete_job to suspend user {user_id} deployments...")
            suspended_jobs = await self.cluster.delete_job(user_id)
            
            self.assertIn(original_job_id, suspended_jobs)
            self.assertEqual(len(suspended_jobs), 1)
            LOGGER.info(f"âœ… Suspended jobs: {suspended_jobs}")
            
            # 4. éªŒè¯ deployment ä»ç„¶å­˜åœ¨ï¼Œä½†è¢«æš‚åœäº†
            if self.is_real_k8s:
                # ç­‰å¾…æš‚åœç”Ÿæ•ˆ
                await aio.sleep(3)
                
                # æ£€æŸ¥ deployment ä»ç„¶å­˜åœ¨
                try:
                    suspended_deployment = await aio.to_thread(
                        self.cluster.apps_v1.read_namespaced_deployment,
                        name=original_job_id,
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    )
                    
                    # éªŒè¯ deployment å­˜åœ¨
                    self.assertIsNotNone(suspended_deployment)
                    LOGGER.info("âœ… Deployment still exists after suspension")
                    
                    # éªŒè¯å‰¯æœ¬æ•°è¢«è®¾ç½®ä¸º 0
                    self.assertEqual(suspended_deployment.spec.replicas, 0)
                    LOGGER.info(f"âœ… Replicas set to 0: {suspended_deployment.spec.replicas}")
                    
                    # éªŒè¯æ³¨è§£è¢«æ­£ç¡®è®¾ç½®
                    annotations = suspended_deployment.metadata.annotations or {}
                    self.assertEqual(annotations.get("yatcc-se/suspended"), "true")
                    self.assertEqual(annotations.get("yatcc-se/original-replicas"), str(original_replicas))
                    
                    LOGGER.info(f"âœ… Suspension annotations set correctly:")
                    LOGGER.info(f"   - suspended: {annotations.get('yatcc-se/suspended')}")
                    LOGGER.info(f"   - original-replicas: {annotations.get('yatcc-se/original-replicas')}")
                    
                    # éªŒè¯å…¶ä»–é…ç½®ä¿¡æ¯ä¿æŒä¸å˜
                    container = suspended_deployment.spec.template.spec.containers[0]
                    env_dict = {env_var.name: env_var.value for env_var in (container.env or [])}
                    
                    self.assertEqual(container.image, job_params.image)
                    self.assertEqual(env_dict.get("TEST_VAR"), "original_value")
                    LOGGER.info("âœ… Original configuration preserved")
                    
                except Exception as e:
                    self.fail(f"Deployment should still exist after suspension: {e}")
            
            # 5. éªŒè¯ä½œä¸šçŠ¶æ€åæ˜ äº†æš‚åœçŠ¶æ€
            try:
                suspended_status = await self.cluster.get_job_status(original_job_id)
                # æš‚åœåçŠ¶æ€åº”è¯¥ä¸æ˜¯ RUNNING
                if suspended_status == JobInfo.Status.RUNNING:
                    LOGGER.warning("âš ï¸  Status still shows RUNNING after suspension")
                else:
                    LOGGER.info(f"âœ… Status after suspension: {suspended_status}")
            except JobNotFoundError:
                self.fail("Job should still be found after suspension")
            
            # 6. éªŒè¯å¯ä»¥è·å–ä½œä¸šä¿¡æ¯ï¼ˆä½†çŠ¶æ€å¯èƒ½ä¸åŒï¼‰
            try:
                suspended_job_info = await self.cluster.get_job_info(original_job_id)
                self.assertEqual(suspended_job_info.id, original_job_id)
                self.assertEqual(suspended_job_info.user_id, user_id)
                self.assertEqual(suspended_job_info.env.get("TEST_VAR"), "original_value")
                LOGGER.info("âœ… Job info still accessible after suspension")
            except JobNotFoundError:
                self.fail("Job info should still be accessible after suspension")
            
            # 7. éªŒè¯å†æ¬¡æäº¤ç›¸åŒç”¨æˆ·çš„ä½œä¸šä¼šæ¢å¤åŸæ¥çš„ deployment
            LOGGER.info(f"ğŸ”„ Testing recovery by submitting new job for user {user_id}...")
            
            recovery_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="recovery-test",
                memory_limit="512Mi",  # ä¸åŒçš„é…ç½®
                env={"TEST_VAR": "updated_value", "NEW_VAR": "added"}
            )
            
            recovered_job_info = await self.cluster.submit_job(recovery_params)
            
            # å¦‚æœæ˜¯ç›¸åŒçš„ deployment IDï¼Œè¯´æ˜æ¢å¤äº†åŸæ¥çš„
            if recovered_job_info.id == original_job_id:
                LOGGER.info("âœ… Original deployment was recovered and updated")
                self.assertEqual(recovered_job_info.id, original_job_id)
                
                # éªŒè¯é…ç½®è¢«æ›´æ–°äº†
                if self.is_real_k8s:
                    await aio.sleep(3)  # ç­‰å¾…æ›´æ–°ç”Ÿæ•ˆ
                    
                    recovered_deployment = await aio.to_thread(
                        self.cluster.apps_v1.read_namespaced_deployment,
                        name=original_job_id,
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    )
                    
                    # éªŒè¯å‰¯æœ¬æ•°æ¢å¤äº†
                    self.assertGreater(recovered_deployment.spec.replicas, 0)
                    LOGGER.info(f"âœ… Replicas restored to: {recovered_deployment.spec.replicas}")
            else:
                LOGGER.info("â„¹ï¸  New deployment created (old one replaced)")
                self.track_job(recovered_job_info.id)
            
            # 8. éªŒè¯ list_jobs ä¸­èƒ½çœ‹åˆ°æ¢å¤çš„ä½œä¸š
            all_jobs = await self.cluster.list_jobs()
            active_user_jobs = [job for job in all_jobs if job.user_id == user_id]
            
            self.assertGreater(len(active_user_jobs), 0)
            LOGGER.info(f"âœ… Found {len(active_user_jobs)} active jobs for user {user_id}")
            
            return {
                'original_job_id': original_job_id,
                'suspended_jobs': suspended_jobs,
                'recovered_job_info': recovered_job_info
            }
        
        return RUNNER.run(test_logic())

    def test_delete_job_nonexistent_user(self):
        """æµ‹è¯•å¯¹ä¸å­˜åœ¨çš„ç”¨æˆ·è°ƒç”¨ delete_job"""
        async def test_logic():
            LOGGER.info("ğŸ§ª Testing delete_job with nonexistent user...")
            
            nonexistent_user_id = 9999
            
            # è°ƒç”¨ delete_job å¯¹ä¸å­˜åœ¨çš„ç”¨æˆ·
            try:
                suspended_jobs = await self.cluster.delete_job(nonexistent_user_id)
                
                # åº”è¯¥è¿”å›ç©ºåˆ—è¡¨ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                self.assertEqual(suspended_jobs, [])
                LOGGER.info(f"âœ… No jobs suspended for nonexistent user {nonexistent_user_id}")
                
            except JobNotFoundError:
                LOGGER.info("â„¹ï¸  JobNotFoundError raised for nonexistent user (acceptable)")
            except Exception as e:
                self.fail(f"Unexpected exception for nonexistent user: {e}")
            
            return True
        
        return RUNNER.run(test_logic())

    def test_get_service_url_connectivity(self):
        """æµ‹è¯• get_service_url æ–¹æ³•å¹¶éªŒè¯ç«¯å£è”é€šæ€§"""
        async def test_logic():
            LOGGER.info("ğŸ§ª Testing get_service_url and port connectivity...")
            
            user_id = 6001
            
            # 1. åˆ›å»ºæµ‹è¯•ä½œä¸š
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="connectivity-test",
                memory_limit="512Mi",
                cpu_limit="500m",  # æ·»åŠ  CPU é™åˆ¶
                env={"TEST_ENV": "connectivity_test"}
            )
            
            LOGGER.info(f"ğŸ“ Creating job for connectivity test (user {user_id})...")
            job_info = await self.cluster.submit_job(job_params)
            self.track_job(job_info.id)
            
            LOGGER.info(f"âœ… Job created: {job_info.id}")
            LOGGER.info(f"ğŸ“ Initial service URL: {job_info.service_url}")
            
            if self.is_real_k8s:
                # 2. ç­‰å¾… Pod å°±ç»ªï¼Œè€Œä¸æ˜¯ç«‹å³å°è¯•ç«¯å£è½¬å‘
                LOGGER.info("â³ Waiting for Pod to be ready...")
                
                pod_ready = await self._wait_for_pod_ready(job_info.id, timeout=120)
                
                if not pod_ready:
                    LOGGER.warning("âš ï¸  Pod did not become ready within timeout")
                    await self._debug_pod_status(job_info.id)
                    await self._debug_service_status(job_info.id)
                    
                    # å³ä½¿ Pod æ²¡æœ‰å°±ç»ªï¼Œæˆ‘ä»¬ä»ç„¶æµ‹è¯• get_service_url çš„åŠŸèƒ½
                    LOGGER.info("ğŸ”— Testing get_service_url even though Pod is not ready...")
                else:
                    LOGGER.info("âœ… Pod is ready, proceeding with connectivity tests")
            
            # 3. è·å–æœåŠ¡ URL
            LOGGER.info(f"ğŸ”— Getting service URL for job {job_info.id}...")
            
            try:
                service_url = await self.cluster.get_service_url(job_info.id)
                
                self.assertIsNotNone(service_url)
                LOGGER.info(f"ğŸŒ Service URL: {service_url}")
                
                # 4. è§£æ URL è·å–ä¸»æœºå’Œç«¯å£
                parsed_url = urlparse(service_url)
                host = parsed_url.hostname
                port = parsed_url.port
                
                LOGGER.info(f"ğŸ” Parsed URL components:")
                LOGGER.info(f"  - Scheme: {parsed_url.scheme}")
                LOGGER.info(f"  - Host: {host}")
                LOGGER.info(f"  - Port: {port}")
                
                # éªŒè¯ URL æ ¼å¼
                self.assertIn(parsed_url.scheme, ['http', 'https'])
                self.assertIsNotNone(host)
                self.assertIsNotNone(port)
                
                if self.is_real_k8s:
                    # 5. åªæœ‰åœ¨ Pod å°±ç»ªçš„æƒ…å†µä¸‹æ‰æµ‹è¯•è¿é€šæ€§
                    if pod_ready:
                        # éªŒè¯ä½œä¸šçŠ¶æ€
                        job_status = await self.cluster.get_job_status(job_info.id)
                        LOGGER.info(f"ğŸ“Š Job status: {job_status}")
                        
                        # 6. æµ‹è¯•ç«¯å£è¿é€šæ€§
                        LOGGER.info(f"ğŸ”Œ Testing port connectivity to {host}:{port}...")
                        
                        port_open = await self._test_port_connectivity(host, port, timeout=10)
                        
                        if port_open:
                            LOGGER.info(f"âœ… Port {port} on {host} is accessible")
                            
                            # 7. æµ‹è¯• HTTP è¿æ¥
                            LOGGER.info(f"ğŸŒ Testing HTTP connectivity to {service_url}...")
                            
                            http_accessible = await self._test_http_connectivity(service_url)
                            
                            if http_accessible:
                                LOGGER.info(f"âœ… HTTP connection to {service_url} successful")
                            else:
                                LOGGER.warning(f"âš ï¸  HTTP connection to {service_url} failed")
                        else:
                            LOGGER.warning(f"âš ï¸  Port {port} on {host} is not accessible")
                            LOGGER.info("ğŸ’¡ This may be expected if the port forward setup failed")
                    else:
                        LOGGER.info("â­ï¸  Skipping connectivity tests due to Pod not being ready")
                    
                    # 8. éªŒè¯å¤šæ¬¡è°ƒç”¨ get_service_url è¿”å›ä¸€è‡´ç»“æœ
                    LOGGER.info("ğŸ”„ Testing consistency of get_service_url...")
                    
                    for i in range(3):
                        url_check = await self.cluster.get_service_url(job_info.id)
                        self.assertEqual(url_check, service_url)
                        LOGGER.info(f"âœ… Consistency check {i+1}: {url_check}")
                        await aio.sleep(1)
                    
                else:
                    # 9. å¯¹äº Mock é›†ç¾¤çš„æµ‹è¯•
                    LOGGER.info("ğŸ­ Testing mock cluster service URL...")
                    
                    # Mock é›†ç¾¤åº”è¯¥è¿”å›æœ‰æ•ˆçš„ URL æ ¼å¼
                    self.assertTrue(service_url.startswith('http'))
                    LOGGER.info(f"âœ… Mock service URL format is valid: {service_url}")
                
                return {
                    'job_id': job_info.id,
                    'service_url': service_url,
                    'host': host,
                    'port': port,
                    'user_id': user_id,
                    'pod_ready': pod_ready if self.is_real_k8s else True
                }
                
            except Exception as e:
                LOGGER.error(f"âŒ get_service_url failed: {e}")
                
                if self.is_real_k8s:
                    await self._debug_pod_status(job_info.id)
                    await self._debug_service_status(job_info.id)
                
                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿æµ‹è¯•å¤±è´¥
                raise
        
        return RUNNER.run(test_logic())

    async def _wait_for_pod_ready(self, job_id: str, timeout: int = 120) -> bool:
        """ç­‰å¾… Pod å˜ä¸ºå°±ç»ªçŠ¶æ€"""
        LOGGER.info(f"â³ Waiting for Pod {job_id} to be ready (timeout: {timeout}s)...")
        
        start_time = aio.get_event_loop().time()
        
        while True:
            try:
                pods = await aio.to_thread(
                    self.cluster.core_v1.list_namespaced_pod,
                    namespace=self.cluster.config.Kubernetes.NAMESPACE,
                    label_selector=f"app={job_id}"
                )
                
                if not pods.items:
                    LOGGER.debug(f"No pods found for job {job_id}")
                    await aio.sleep(5)
                    continue
                
                pod = pods.items[0]  # å–ç¬¬ä¸€ä¸ª Pod
                pod_name = pod.metadata.name
                pod_phase = pod.status.phase
                
                LOGGER.debug(f"Pod {pod_name} phase: {pod_phase}")
                
                if pod_phase == "Running":
                    # æ£€æŸ¥å®¹å™¨æ˜¯å¦éƒ½å°±ç»ª
                    if pod.status.container_statuses:
                        all_ready = all(cs.ready for cs in pod.status.container_statuses)
                        if all_ready:
                            LOGGER.info(f"âœ… Pod {pod_name} is running and all containers are ready")
                            return True
                        else:
                            LOGGER.debug(f"Pod {pod_name} running but containers not all ready")
                    else:
                        LOGGER.debug(f"Pod {pod_name} running but no container status available")
                
                elif pod_phase == "Pending":
                    # æ£€æŸ¥ Pending çš„åŸå› 
                    if pod.status.conditions:
                        for condition in pod.status.conditions:
                            if condition.status == "False":
                                LOGGER.debug(f"Pod condition: {condition.type} - {condition.reason}: {condition.message}")
                    
                    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                    if pod.status.container_statuses:
                        for cs in pod.status.container_statuses:
                            if cs.state.waiting:
                                reason = cs.state.waiting.reason
                                message = cs.state.waiting.message
                                LOGGER.debug(f"Container {cs.name} waiting: {reason} - {message}")
                                
                                # å¦‚æœæ˜¯é•œåƒæ‹‰å–é—®é¢˜ï¼Œç»™æ›´å¤šæ—¶é—´
                                if reason in ["ImagePullBackOff", "ErrImagePull"]:
                                    LOGGER.warning(f"âš ï¸  Image pull issues detected for {cs.name}")
                
                elif pod_phase == "Failed":
                    LOGGER.error(f"âŒ Pod {pod_name} failed")
                    await self._debug_pod_status(job_id)
                    return False
                    
            except Exception as e:
                LOGGER.warning(f"Error checking pod status: {e}")
            
            # æ£€æŸ¥è¶…æ—¶
            elapsed = aio.get_event_loop().time() - start_time
            if elapsed > timeout:
                LOGGER.warning(f"â° Timeout waiting for Pod {job_id} to be ready after {timeout}s")
                return False
            
            await aio.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•

    async def _debug_pod_status(self, job_id: str):
        """è°ƒè¯• Pod çŠ¶æ€"""
        # ... (ä¿æŒä¹‹å‰çš„å®ç°)
        try:
            LOGGER.info(f"ğŸ” Debugging Pod status for job {job_id}...")
            
            pods = await aio.to_thread(
                self.cluster.core_v1.list_namespaced_pod,
                namespace=self.cluster.config.Kubernetes.NAMESPACE,
                label_selector=f"app={job_id}"
            )
            
            if not pods.items:
                LOGGER.warning(f"âŒ No pods found for job {job_id}")
                return
            
            for pod in pods.items:
                pod_name = pod.metadata.name
                pod_phase = pod.status.phase
                
                LOGGER.info(f"ğŸ“¦ Pod: {pod_name}")
                LOGGER.info(f"  - Phase: {pod_phase}")
                LOGGER.info(f"  - Node: {pod.spec.node_name or 'Not assigned'}")
                LOGGER.info(f"  - Creation time: {pod.metadata.creation_timestamp}")
                
                # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                if pod.status.container_statuses:
                    LOGGER.info(f"  - Container statuses:")
                    for container_status in pod.status.container_statuses:
                        LOGGER.info(f"    ğŸ“¦ Container {container_status.name}:")
                        LOGGER.info(f"      - Ready: {container_status.ready}")
                        LOGGER.info(f"      - Restart count: {container_status.restart_count}")
                        LOGGER.info(f"      - Image: {container_status.image}")
                        
                        if container_status.state.waiting:
                            waiting = container_status.state.waiting
                            LOGGER.warning(f"      â³ Waiting: {waiting.reason}")
                            if waiting.message:
                                LOGGER.warning(f"         Message: {waiting.message}")
                        elif container_status.state.running:
                            running = container_status.state.running
                            LOGGER.info(f"      âœ… Running since: {running.started_at}")
                        elif container_status.state.terminated:
                            terminated = container_status.state.terminated
                            LOGGER.error(f"      âŒ Terminated: {terminated.reason}")
                            if terminated.message:
                                LOGGER.error(f"         Message: {terminated.message}")
                            LOGGER.error(f"         Exit code: {terminated.exit_code}")
        
        except Exception as e:
            LOGGER.error(f"Failed to debug pod status: {e}")

    async def _debug_service_status(self, job_id: str):
        """è°ƒè¯• Service çŠ¶æ€"""
        # ... (ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å®ç°)
        try:
            LOGGER.info(f"ğŸ” Debugging Service status for job {job_id}...")
            
            service_name = f"{job_id}-svc"
            
            try:
                service = await aio.to_thread(
                    self.cluster.core_v1.read_namespaced_service,
                    name=service_name,
                    namespace=self.cluster.config.Kubernetes.NAMESPACE
                )
                
                LOGGER.info(f"ğŸŒ Service: {service.metadata.name}")
                LOGGER.info(f"  - Type: {service.spec.type}")
                LOGGER.info(f"  - Cluster IP: {service.spec.cluster_ip}")
                
                # æ˜¾ç¤ºç«¯å£ä¿¡æ¯
                if service.spec.ports:
                    LOGGER.info(f"  - Ports:")
                    for port in service.spec.ports:
                        LOGGER.info(f"    ğŸ“Œ {port.name or 'unnamed'}: {port.port}/{port.protocol}")
                        if port.target_port:
                            LOGGER.info(f"      Target port: {port.target_port}")
                
                # æ˜¾ç¤ºé€‰æ‹©å™¨
                if service.spec.selector:
                    LOGGER.info(f"  - Selector:")
                    for key, value in service.spec.selector.items():
                        LOGGER.info(f"    {key}: {value}")
                
            except Exception as e:
                if "not found" in str(e).lower():
                    LOGGER.warning(f"âŒ Service {service_name} not found")
                else:
                    LOGGER.error(f"Failed to get service {service_name}: {e}")
        
        except Exception as e:
            LOGGER.error(f"Failed to debug service status: {e}")

    async def _test_port_connectivity(self, host: str, port: int, timeout: int = 5) -> bool:
        """æµ‹è¯•ç«¯å£è¿é€šæ€§"""
        # ... (ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å®ç°)
        try:
            future = aio.get_event_loop().run_in_executor(
                None, 
                self._sync_test_port_connectivity, 
                host, port, timeout
            )
            return await future
        except Exception as e:
            LOGGER.warning(f"Port connectivity test failed: {e}")
            return False

    def _sync_test_port_connectivity(self, host: str, port: int, timeout: int) -> bool:
        """åŒæ­¥æµ‹è¯•ç«¯å£è¿é€šæ€§"""
        # ... (ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å®ç°)
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(timeout)
                result = sock.connect_ex((host, port))
                return result == 0
        except Exception as e:
            LOGGER.debug(f"Socket connection failed: {e}")
            return False

    async def _test_http_connectivity(self, url: str, timeout: int = 10) -> bool:
        """æµ‹è¯• HTTP è¿é€šæ€§"""
        # ... (ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å®ç°)
        try:
            future = aio.get_event_loop().run_in_executor(
                None, 
                self._sync_test_http_connectivity, 
                url, timeout
            )
            return await future
        except Exception as e:
            LOGGER.warning(f"HTTP connectivity test failed: {e}")
            return False

    def _sync_test_http_connectivity(self, url: str, timeout: int) -> bool:
        """åŒæ­¥æµ‹è¯• HTTP è¿é€šæ€§"""
        # ... (ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å®ç°)
        try:
            req = urllib.request.Request(url, headers={
                'User-Agent': 'YatCC-SE-Test/1.0'
            })
            
            with urllib.request.urlopen(req, timeout=timeout) as response:
                status_code = response.getcode()
                LOGGER.debug(f"HTTP response status: {status_code}")
                return status_code in [200, 302, 401, 403]
                
        except urllib.error.HTTPError as e:
            LOGGER.debug(f"HTTP error: {e.code}")
            return e.code in [401, 403, 404, 500]
            
        except Exception as e:
            LOGGER.debug(f"HTTP test exception: {e}")
            return False


if __name__ == '__main__':
    unittest.main()