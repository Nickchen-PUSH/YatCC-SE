"""Kubernetes é›†ç¾¤æµ‹è¯•

æµ‹è¯• Kubernetes é›†ç¾¤çš„ç”¨æˆ·ç‹¬ç«‹ code-server éƒ¨ç½²åŠŸèƒ½ã€‚
"""

import unittest
import asyncio as aio
from cluster import JobInfo, ClusterError, JobNotFoundError
from base.logger import logger
from . import ClusterTestBase, RUNNER, get_kubernetes_cluster, ensure_kubernetes_cluster

LOGGER = logger(__spec__, __file__)


def setUpModule() -> None:
    """æ¨¡å—çº§åˆ«çš„è®¾ç½®"""
    LOGGER.info("ğŸš€ Kubernetes cluster test module setup")
    # é¢„å…ˆåˆå§‹åŒ– Kubernetes é›†ç¾¤
    try:
        k8s_cluster = ensure_kubernetes_cluster()
        if k8s_cluster:
            LOGGER.info(f"âœ… Kubernetes cluster ready for testing: {k8s_cluster.__class__.__name__}")
        else:
            LOGGER.warning("âš ï¸  No Kubernetes cluster available")
    except Exception as e:
        LOGGER.warning(f"âš ï¸  Failed to setup Kubernetes cluster: {e}")


def tearDownModule() -> None:
    """æ¨¡å—çº§åˆ«çš„æ¸…ç†"""
    LOGGER.info("ğŸ§¹ Kubernetes cluster test module teardown")


class KubernetesClusterTest(ClusterTestBase):
    """Kubernetes é›†ç¾¤åŠŸèƒ½æµ‹è¯•"""
    
    def setUp(self) -> None:
        """æµ‹è¯•è®¾ç½®"""
        super().setUp()
        
        # è·å– Kubernetes é›†ç¾¤
        k8s_cluster = get_kubernetes_cluster()
        
        if k8s_cluster is None:
            self.skipTest("No Kubernetes cluster available for testing")
        
        self.cluster = k8s_cluster
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®çš„ Kubernetes é›†ç¾¤
        is_mock = getattr(self.cluster, '_is_mock', True)
        if is_mock:
            LOGGER.info(f"Using MOCK cluster for Kubernetes tests: {self.cluster.__class__.__name__}")
            self.is_real_k8s = False
        else:
            LOGGER.info(f"Using REAL Kubernetes cluster: {self.cluster.__class__.__name__}")
            self.is_real_k8s = True
        
        self.assertIsNotNone(self.cluster, "Kubernetes cluster should be available")
    
    def test_submit_user_code_server_deployment(self):
        """æµ‹è¯•æäº¤ç”¨æˆ·ç‹¬ç«‹çš„ code-server Deployment"""
        async def _test():
            user_id = 6001
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="my-workspace",
                cpu_limit="2000m",
                memory_limit="4Gi",
                storage_size="10Gi"
            )
            
            job_info = await self.cluster.submit_job(job_params)
            self.track_job(job_info.id)
            
            # éªŒè¯ä½œä¸šä¿¡æ¯
            self.assert_code_server_job_valid(job_info)
            self.assert_user_isolation(job_info, user_id)
            self.assertIsNotNone(job_info.service_url)
            
            # æ ¹æ®é›†ç¾¤ç±»å‹è¿›è¡Œä¸åŒçš„éªŒè¯
            if self.is_real_k8s:
                # çœŸå® K8s é›†ç¾¤çš„éªŒè¯
                self.assertEqual(job_info.namespace, "default")
                # éªŒè¯çœŸå®çš„ service URL æ ¼å¼
                self.assertIn(":", job_info.service_url)
            else:
                # Mock é›†ç¾¤çš„éªŒè¯
                self.assertIsNotNone(job_info.namespace)
            
            # éªŒè¯ä½œä¸šåç§°æ ¼å¼ï¼ˆç”¨æˆ·ç‹¬ç«‹ï¼‰
            self.assertIn("code-server", job_info.name)
            self.assertIn(f"{user_id}", job_info.name)
            
            LOGGER.info(f"User {user_id} code-server job submitted: {job_info.id} (Real K8s: {self.is_real_k8s})")
        
        RUNNER.run(_test())
    
    def test_persistent_storage_per_user(self):
        """æµ‹è¯•æ¯ä¸ªç”¨æˆ·çš„æŒä¹…åŒ–å­˜å‚¨"""
        async def _test():
            user_id = 6003
            storage_size = "25Gi"
            
            job_params = self.create_code_server_params(
                user_id=user_id,
                storage_size=storage_size
            )
            
            job_info = await self.cluster.submit_job(job_params)
            self.track_job(job_info.id)
            
            # éªŒè¯ç”¨æˆ·ç‹¬ç«‹å­˜å‚¨é…ç½®
            self.assert_code_server_job_valid(job_info)
            self.assert_user_isolation(job_info, user_id)
            
            LOGGER.info(f"User {user_id} persistent storage configured: {storage_size} (Real K8s: {self.is_real_k8s})")
        
        RUNNER.run(_test())
    
    def test_user_environment_customization(self):
        """æµ‹è¯•ç”¨æˆ·ç¯å¢ƒè‡ªå®šä¹‰"""
        async def _test():
            user_id = 6005
            custom_env = {
                "EXTENSIONS": "ms-python.python,ms-vscode.vscode-json",
                "CUSTOM_VAR": f"user_{user_id}_value",
                "WORKSPACE_TYPE": "development"
            }
            
            job_params = self.create_code_server_params(
                user_id=user_id,
                env=custom_env
            )
            
            job_info = await self.cluster.submit_job(job_params)
            self.track_job(job_info.id)
            
            # éªŒè¯ç”¨æˆ·è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
            self.assert_user_isolation(job_info, user_id)
            self.assertIn("PASSWORD", job_info.env)
            
            # æ£€æŸ¥è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ï¼ˆä»…åœ¨æ”¯æŒçš„é›†ç¾¤ä¸­ï¼‰
            if "CUSTOM_VAR" in job_info.env:
                self.assertEqual(job_info.env.get("CUSTOM_VAR"), f"user_{user_id}_value")
            if "EXTENSIONS" in job_info.env:
                self.assertEqual(job_info.env.get("EXTENSIONS"), "ms-python.python,ms-vscode.vscode-json")
            
            LOGGER.info(f"User {user_id} environment customization verified (Real K8s: {self.is_real_k8s})")
        
        RUNNER.run(_test())
        
    def test_delete_code_server_job(self):
        """æµ‹è¯•åˆ é™¤ code-server ä½œä¸š"""
        async def _test():
            user_id = 9001
            
            # 1. åˆ›å»ºä½œä¸š
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="delete-test"
            )
            
            job_info = await self.cluster.submit_job(job_params)
            job_id = job_info.id
            
            # éªŒè¯ä½œä¸šåˆ›å»ºæˆåŠŸ
            self.assert_code_server_job_valid(job_info)
            self.assert_user_isolation(job_info, user_id)
            
            LOGGER.info(f"Created job for deletion test: {job_id}")
            
            # 2. éªŒè¯ä½œä¸šå­˜åœ¨
            retrieved_job = await self.cluster.get_job_info(job_id)
            self.assertEqual(retrieved_job.id, job_id)
            self.assertEqual(retrieved_job.user_id, user_id)
            
            # 3. åˆ é™¤ä½œä¸š
            await self.cluster.delete_job(job_id)
            LOGGER.info(f"Deleted job: {job_id}")
            
            # 4. éªŒè¯ä½œä¸šå·²è¢«åˆ é™¤ - åº”è¯¥æŠ›å‡º JobNotFoundError
            with self.assertRaises(JobNotFoundError):
                await self.cluster.get_job_info(job_id)
            
            # 5. éªŒè¯ä½œä¸šä¸åœ¨åˆ—è¡¨ä¸­
            jobs = await self.cluster.list_jobs()
            job_ids = [job.id for job in jobs]
            self.assertNotIn(job_id, job_ids)
            
            LOGGER.info(f"âœ… Job {job_id} successfully deleted and verified")
            
        RUNNER.run(_test())
    
    def test_delete_nonexistent_job(self):
        """æµ‹è¯•åˆ é™¤ä¸å­˜åœ¨çš„ä½œä¸š"""
        async def _test():
            nonexistent_job_id = "nonexistent-job-12345"
            
            # åˆ é™¤ä¸å­˜åœ¨çš„ä½œä¸šåº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸ï¼ˆå¹‚ç­‰æ“ä½œï¼‰
            try:
                await self.cluster.delete_job(nonexistent_job_id)
                LOGGER.info(f"âœ… Deleting nonexistent job {nonexistent_job_id} handled gracefully")
            except Exception as e:
                # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œåº”è¯¥æ˜¯å¯æ¥å—çš„å¼‚å¸¸ç±»å‹
                LOGGER.info(f"Delete nonexistent job threw: {type(e).__name__}: {e}")
                # åœ¨çœŸå®çš„ K8s é›†ç¾¤ä¸­ï¼Œåˆ é™¤ä¸å­˜åœ¨çš„èµ„æºé€šå¸¸ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
                if self.is_real_k8s:
                    # å¯¹äºçœŸå®é›†ç¾¤ï¼Œæˆ‘ä»¬æœŸæœ›æ“ä½œæ˜¯å¹‚ç­‰çš„
                    pass
                else:
                    # Mock é›†ç¾¤å¯èƒ½æœ‰ä¸åŒçš„è¡Œä¸º
                    pass
            
        RUNNER.run(_test())
    
    def test_delete_multiple_user_jobs(self):
        """æµ‹è¯•åˆ é™¤å¤šä¸ªç”¨æˆ·çš„ä½œä¸š"""
        async def _test():
            user_ids = [9101, 9102, 9103]
            created_jobs = []
            
            # 1. ä¸ºå¤šä¸ªç”¨æˆ·åˆ›å»ºä½œä¸š
            for user_id in user_ids:
                job_params = self.create_code_server_params(
                    user_id=user_id,
                    workspace_name=f"multi-delete-{user_id}"
                )
                
                job_info = await self.cluster.submit_job(job_params)
                created_jobs.append((job_info.id, user_id))
                
                # éªŒè¯åˆ›å»º
                self.assert_user_isolation(job_info, user_id)
            
            LOGGER.info(f"Created {len(created_jobs)} jobs for multi-delete test")
            
            # 2. éªŒè¯æ‰€æœ‰ä½œä¸šéƒ½å­˜åœ¨
            initial_jobs = await self.cluster.list_jobs()
            initial_job_ids = [job.id for job in initial_jobs]
            
            for job_id, user_id in created_jobs:
                self.assertIn(job_id, initial_job_ids)
            
            # 3. é€ä¸€åˆ é™¤ä½œä¸š
            for job_id, user_id in created_jobs:
                await self.cluster.delete_job(job_id)
                LOGGER.info(f"Deleted job {job_id} for user {user_id}")
                
                # éªŒè¯å•ä¸ªä½œä¸šè¢«åˆ é™¤
                with self.assertRaises(JobNotFoundError):
                    await self.cluster.get_job_info(job_id)
            
            # 4. éªŒè¯æ‰€æœ‰ä½œä¸šéƒ½è¢«åˆ é™¤
            final_jobs = await self.cluster.list_jobs()
            final_job_ids = [job.id for job in final_jobs]
            
            for job_id, user_id in created_jobs:
                self.assertNotIn(job_id, final_job_ids)
            
            LOGGER.info(f"âœ… All {len(created_jobs)} jobs successfully deleted")
            
        RUNNER.run(_test())
    
    def test_delete_job_resources_cleanup(self):
        """æµ‹è¯•åˆ é™¤ä½œä¸šæ—¶èµ„æºæ¸…ç†çš„å®Œæ•´æ€§"""
        async def _test():
            user_id = 9201
            
            # 1. åˆ›å»ºä½œä¸š
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="cleanup-test",
                storage_size="1Gi"
            )
            
            job_info = await self.cluster.submit_job(job_params)
            job_id = job_info.id
            
            LOGGER.info(f"Created job for cleanup test: {job_id}")
            
            # 2. éªŒè¯èµ„æºåˆ›å»ºï¼ˆä»…åœ¨çœŸå® K8s é›†ç¾¤ä¸­ï¼‰
            if self.is_real_k8s:
                # éªŒè¯ Deployment å­˜åœ¨
                try:
                    deployment = await aio.to_thread(
                        self.cluster.apps_v1.read_namespaced_deployment,
                        name=job_id,
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    )
                    self.assertEqual(deployment.metadata.name, job_id)
                    LOGGER.info(f"âœ… Deployment {job_id} verified")
                except Exception as e:
                    LOGGER.warning(f"Could not verify deployment {job_id}: {e}")
                
                # éªŒè¯ Service å­˜åœ¨
                try:
                    service = await aio.to_thread(
                        self.cluster.core_v1.read_namespaced_service,
                        name=f"{job_id}-svc",
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    )
                    self.assertEqual(service.metadata.name, f"{job_id}-svc")
                    LOGGER.info(f"âœ… Service {job_id}-svc verified")
                except Exception as e:
                    LOGGER.warning(f"Could not verify service {job_id}-svc: {e}")
                
                # éªŒè¯ PVC å­˜åœ¨
                try:
                    pvc = await aio.to_thread(
                        self.cluster.core_v1.read_namespaced_persistent_volume_claim,
                        name=f"{job_id}-pvc",
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    )
                    self.assertEqual(pvc.metadata.name, f"{job_id}-pvc")
                    LOGGER.info(f"âœ… PVC {job_id}-pvc verified")
                except Exception as e:
                    LOGGER.warning(f"Could not verify PVC {job_id}-pvc: {e}")
            
            # 3. åˆ é™¤ä½œä¸š
            await self.cluster.delete_job(job_id)
            LOGGER.info(f"Deleted job: {job_id}")
            
            # 4. éªŒè¯æ‰€æœ‰èµ„æºéƒ½è¢«æ¸…ç†ï¼ˆä»…åœ¨çœŸå® K8s é›†ç¾¤ä¸­ï¼‰
            if self.is_real_k8s:
                from kubernetes.client.rest import ApiException
                
                # ç­‰å¾…èµ„æºåˆ é™¤å®Œæˆçš„è¾…åŠ©å‡½æ•°
                async def wait_for_resource_deletion(check_func, resource_name, max_wait=30):
                    """ç­‰å¾…èµ„æºè¢«åˆ é™¤"""
                    start_time = aio.get_event_loop().time()
                    
                    while (aio.get_event_loop().time() - start_time) < max_wait:
                        try:
                            await aio.to_thread(check_func)
                            # å¦‚æœè¿˜èƒ½è¯»å–åˆ°èµ„æºï¼Œç»§ç»­ç­‰å¾…
                            await aio.sleep(2)
                        except ApiException as e:
                            if e.status == 404:
                                LOGGER.info(f"âœ… {resource_name} successfully deleted")
                                return True
                            else:
                                LOGGER.warning(f"Unexpected error checking {resource_name}: {e}")
                                await aio.sleep(2)
                        except Exception as e:
                            LOGGER.warning(f"Error waiting for {resource_name} deletion: {e}")
                            await aio.sleep(2)
                    
                    LOGGER.warning(f"âš ï¸  Timeout waiting for {resource_name} deletion")
                    return False
                
                # ç­‰å¾… Deployment åˆ é™¤
                deployment_deleted = await wait_for_resource_deletion(
                    lambda: self.cluster.apps_v1.read_namespaced_deployment(
                        name=job_id,
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    ),
                    f"Deployment {job_id}"
                )
                
                # ç­‰å¾… Service åˆ é™¤
                service_deleted = await wait_for_resource_deletion(
                    lambda: self.cluster.core_v1.read_namespaced_service(
                        name=f"{job_id}-svc",
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    ),
                    f"Service {job_id}-svc"
                )
                
                # ç­‰å¾… PVC åˆ é™¤
                pvc_deleted = await wait_for_resource_deletion(
                    lambda: self.cluster.core_v1.read_namespaced_persistent_volume_claim(
                        name=f"{job_id}-pvc",
                        namespace=self.cluster.config.Kubernetes.NAMESPACE
                    ),
                    f"PVC {job_id}-pvc"
                )
                
                # éªŒè¯è‡³å°‘ä¸»è¦èµ„æºè¢«åˆ é™¤
                if deployment_deleted and service_deleted:
                    LOGGER.info(f"âœ… All critical resources confirmed deleted for job {job_id}")
                else:
                    LOGGER.warning(f"âš ï¸  Some resources may still exist for job {job_id}")
                    # å¯¹äºæµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥å®¹å¿ PVC åˆ é™¤è¾ƒæ…¢
                    if deployment_deleted:
                        LOGGER.info(f"âœ… Main deployment resource deleted for job {job_id}")
                
            else:
                LOGGER.info(f"âœ… Cleanup test completed (Mock cluster)")
            
            # 5. æœ€ç»ˆéªŒè¯ä½œä¸šä¸å­˜åœ¨
            with self.assertRaises(JobNotFoundError):
                await self.cluster.get_job_info(job_id)
            
        RUNNER.run(_test())
    
    def test_delete_job_error_handling(self):
        """æµ‹è¯•åˆ é™¤ä½œä¸šæ—¶çš„é”™è¯¯å¤„ç†"""
        async def _test():
            user_id = 9203
            
            # 1. åˆ›å»ºä½œä¸š
            job_params = self.create_code_server_params(
                user_id=user_id,
                workspace_name="error-handling-test"
            )
            
            job_info = await self.cluster.submit_job(job_params)
            job_id = job_info.id
            
            LOGGER.info(f"Created job for error handling test: {job_id}")
            
            # 2. æ­£å¸¸åˆ é™¤ä½œä¸š
            await self.cluster.delete_job(job_id)
            LOGGER.info(f"Deleted job: {job_id}")
            
            # 3. å°è¯•åˆ é™¤å·²åˆ é™¤çš„ä½œä¸šï¼ˆåº”è¯¥å¤„ç†ä¼˜é›…ï¼‰
            try:
                await self.cluster.delete_job(job_id)
                LOGGER.info(f"âœ… Re-deletion of {job_id} handled gracefully")
            except Exception as e:
                # è®°å½•å¼‚å¸¸ä½†ä¸å¤±è´¥æµ‹è¯•ï¼Œå› ä¸ºä¸åŒå®ç°å¯èƒ½æœ‰ä¸åŒè¡Œä¸º
                LOGGER.info(f"Re-deletion threw: {type(e).__name__}: {e}")
            
            # 4. å°è¯•åˆ é™¤æ— æ•ˆçš„ä½œä¸šID
            invalid_job_ids = [
                "",  # ç©ºå­—ç¬¦ä¸²
                "invalid-job-name-!@#$%",  # åŒ…å«æ— æ•ˆå­—ç¬¦
                "a" * 100,  # è¿‡é•¿çš„åç§°
            ]
            
            for invalid_id in invalid_job_ids:
                try:
                    await self.cluster.delete_job(invalid_id)
                    LOGGER.info(f"âœ… Deletion of invalid job ID '{invalid_id}' handled")
                except Exception as e:
                    LOGGER.info(f"Deletion of invalid ID '{invalid_id}' threw: {type(e).__name__}")
                    # è¿™æ˜¯å¯æ¥å—çš„è¡Œä¸º
            
            LOGGER.info(f"âœ… Error handling test completed")
            
        RUNNER.run(_test())

    def test_concurrent_job_deletion(self):
        """æµ‹è¯•å¹¶å‘åˆ é™¤ä½œä¸š"""
        async def _test():
            user_id = 9401
            job_count = 3
            created_jobs = []
            
            # 1. åˆ›å»ºå¤šä¸ªä½œä¸š
            for i in range(job_count):
                job_params = self.create_code_server_params(
                    user_id=user_id + i,
                    workspace_name=f"concurrent-delete-{i}"
                )
                
                job_info = await self.cluster.submit_job(job_params)
                created_jobs.append(job_info.id)
            
            LOGGER.info(f"Created {len(created_jobs)} jobs for concurrent deletion test")
            
            # 2. å¹¶å‘åˆ é™¤æ‰€æœ‰ä½œä¸š
            async def delete_single_job(job_id):
                try:
                    await self.cluster.delete_job(job_id)
                    LOGGER.info(f"Concurrently deleted job: {job_id}")
                    return job_id, True, None
                except Exception as e:
                    LOGGER.warning(f"Failed to delete job {job_id}: {e}")
                    return job_id, False, str(e)
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            delete_tasks = [delete_single_job(job_id) for job_id in created_jobs]
            results = await aio.gather(*delete_tasks, return_exceptions=True)
            
            # 3. åˆ†æåˆ é™¤ç»“æœ
            successful_deletions = 0
            failed_deletions = 0
            
            for result in results:
                if isinstance(result, Exception):
                    LOGGER.warning(f"Deletion task failed with exception: {result}")
                    failed_deletions += 1
                else:
                    job_id, success, error = result
                    if success:
                        successful_deletions += 1
                    else:
                        failed_deletions += 1
                        LOGGER.warning(f"Job {job_id} deletion failed: {error}")
            
            LOGGER.info(f"Concurrent deletion results: {successful_deletions} success, {failed_deletions} failed")
            
            # 4. ç­‰å¾…ä¸€æ®µæ—¶é—´è®©åˆ é™¤å®Œæˆ
            await aio.sleep(5)
            
            # 5. éªŒè¯ä½œä¸šæœ€ç»ˆçŠ¶æ€
            remaining_jobs = await self.cluster.list_jobs()
            remaining_job_ids = [job.id for job in remaining_jobs]
            
            jobs_still_exist = []
            for job_id in created_jobs:
                if job_id in remaining_job_ids:
                    jobs_still_exist.append(job_id)
                    try:
                        # å†æ¬¡å°è¯•åˆ é™¤
                        await self.cluster.delete_job(job_id)
                        LOGGER.info(f"Cleaned up remaining job: {job_id}")
                    except Exception as e:
                        LOGGER.warning(f"Failed to clean up job {job_id}: {e}")
            
            if jobs_still_exist:
                LOGGER.warning(f"Some jobs still exist after concurrent deletion: {jobs_still_exist}")
            else:
                LOGGER.info(f"âœ… All jobs successfully removed")
            
            # å¯¹äºæµ‹è¯•é€šè¿‡ï¼Œæˆ‘ä»¬è¦æ±‚è‡³å°‘å¤§éƒ¨åˆ†åˆ é™¤æˆåŠŸ
            success_rate = successful_deletions / len(created_jobs)
            self.assertGreaterEqual(success_rate, 0.5, 
                f"Expected at least 50% deletion success rate, got {success_rate:.2%}")
            
            LOGGER.info(f"âœ… Concurrent deletion test completed with {success_rate:.2%} success rate")
            
        RUNNER.run(_test())


if __name__ == '__main__':
    unittest.main()